Running script with arguments: Namespace(input_channels=45, input_size=[16, 16], modality='hyper', num_classes=3, test_folder=['/mmfs1/gscratch/stf/upanpra/AK_paper_data/16crops/hardwood_vs_softwood/vis/test', '/mmfs1/gscratch/stf/upanpra/AK_paper_data/16crops/hardwood_vs_softwood/chm/test'], train_folder=['/mmfs1/gscratch/stf/upanpra/AK_paper_data/16crops/hardwood_vs_softwood/vis/train', '/mmfs1/gscratch/stf/upanpra/AK_paper_data/16crops/hardwood_vs_softwood/chm/train'])
tensor([ 1.2413e-03,  1.3992e+00,  1.5666e-01,  2.4665e-03,  3.7055e-03,
         2.8208e-01,  2.4620e-01,  1.1281e-02,  5.7995e+07,  3.3269e-01,
         1.0076e+00,  1.0347e+03,  1.0074e+03,  1.0008e+03,  4.0351e+00,
         2.8078e+00,  1.4801e+00,  6.4264e-01,  1.7263e+00,  1.6173e+03,
         7.6670e-01,  3.2386e-01,  2.9248e+00,  4.8894e+00,  1.6173e+03,
         7.6670e-01,  6.7660e-01, -2.4590e-02,  1.6352e-01,  6.7651e-01,
        -6.2282e-02,  1.1902e+00,  6.5222e-01,  4.6292e-02,  6.9664e+00,
         6.5256e-01,  3.7723e-01,  6.9674e+02,  8.9830e-01,  7.0955e-01,
         1.0268e+00,  6.1569e+04,  9.7964e-01,  1.4239e+00,  2.2436e+00])
tensor([4.2835e-04, 4.0767e-01, 6.8023e-02, 1.5014e-03, 1.7588e-03, 4.3323e-02,
        4.0901e-02, 2.5345e-03, 2.5077e+07, 2.5095e-01, 2.5432e-01, 2.0523e+02,
        1.9951e+02, 2.0219e+02, 5.4792e-01, 3.3658e-01, 1.8284e-01, 8.7965e-02,
        4.7020e-01, 3.2467e+02, 4.8012e-02, 3.8059e-02, 5.3951e-01, 9.9058e-01,
        3.2467e+02, 4.8012e-02, 4.9931e-02, 3.5875e-02, 6.8917e-02, 4.9927e-02,
        1.4947e-02, 1.0155e-01, 4.8966e-02, 1.9410e-02, 1.3976e+00, 1.7419e-01,
        3.9700e-02, 9.5890e+00, 5.9467e-02, 9.4901e-02, 3.9157e-01, 1.2540e+04,
        2.3095e-01, 7.1845e-02, 1.7827e+00])
Saving model to: /mmfs1/gscratch/stf/upanpra/model_checkpointsAK/best-test-model-Visconv_next_model-1700273477.4442928.pt
shape of mean, torch.Size([45])
shape of std, torch.Size([45])
ConvNeXt(
  (features): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(45, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)
    )
    (1): Dropout(p=0.0, inplace=False)
    (2): Sequential(
      (0): CNBlock(
        (block): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (1): Dropout(p=0.0, inplace=False)
          (2): Permute()
          (3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (4): Linear(in_features=128, out_features=512, bias=True)
          (5): GELU()
          (6): Linear(in_features=512, out_features=128, bias=True)
          (7): Permute()
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): CNBlock(
        (block): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (1): Dropout(p=0.0, inplace=False)
          (2): Permute()
          (3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (4): Linear(in_features=128, out_features=512, bias=True)
          (5): GELU()
          (6): Linear(in_features=512, out_features=128, bias=True)
          (7): Permute()
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (2): CNBlock(
        (block): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (1): Dropout(p=0.0, inplace=False)
          (2): Permute()
          (3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (4): Linear(in_features=128, out_features=512, bias=True)
          (5): GELU()
          (6): Linear(in_features=512, out_features=128, bias=True)
          (7): Permute()
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
    )
    (3): Sequential(
      (0): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)
      (1): Conv2d(128, 192, kernel_size=(2, 2), stride=(2, 2))
    )
    (4): Sequential(
      (0): CNBlock(
        (block): Sequential(
          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
          (1): Dropout(p=0.0, inplace=False)
          (2): Permute()
          (3): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (4): Linear(in_features=192, out_features=768, bias=True)
          (5): GELU()
          (6): Linear(in_features=768, out_features=192, bias=True)
          (7): Permute()
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (final_dropout): Dropout(p=0.0, inplace=False)
  (classifier): Sequential(
    (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Linear(in_features=192, out_features=3, bias=True)
  )
)
28337891.291474093
Epoch [1/100], Step [100/178], Loss: 1.0667
Epoch [1/100], Train Acc 67.75%, Test Acc 64.04%
Epoch [2/100], Step [100/178], Loss: 0.9526
Epoch [2/100], Train Acc 71.45%, Test Acc 67.50%
Epoch [3/100], Step [100/178], Loss: 0.5049
Epoch [3/100], Train Acc 72.65%, Test Acc 70.26%
Epoch [4/100], Step [100/178], Loss: 0.6990
Epoch [4/100], Train Acc 74.24%, Test Acc 71.23%
Epoch [5/100], Step [100/178], Loss: 0.6854
Epoch [5/100], Train Acc 75.37%, Test Acc 73.03%
Epoch [6/100], Step [100/178], Loss: 0.7788
Epoch [6/100], Train Acc 74.63%, Test Acc 73.44%
Epoch [7/100], Step [100/178], Loss: 0.4383
Epoch [7/100], Train Acc 76.15%, Test Acc 72.61%
Epoch [8/100], Step [100/178], Loss: 0.9186
Epoch [8/100], Train Acc 73.39%, Test Acc 70.82%
Epoch [9/100], Step [100/178], Loss: 0.5349
Epoch [9/100], Train Acc 73.99%, Test Acc 69.43%
Epoch [10/100], Step [100/178], Loss: 0.5047
Epoch [10/100], Train Acc 75.30%, Test Acc 70.82%
Epoch [11/100], Step [100/178], Loss: 0.3030
Epoch [11/100], Train Acc 76.64%, Test Acc 71.37%
Epoch [12/100], Step [100/178], Loss: 0.5849
Epoch [12/100], Train Acc 77.31%, Test Acc 72.20%
Epoch [13/100], Step [100/178], Loss: 0.5248
Epoch [13/100], Train Acc 77.88%, Test Acc 71.78%
Epoch [14/100], Step [100/178], Loss: 0.9090
Epoch [14/100], Train Acc 76.85%, Test Acc 69.43%
Epoch [15/100], Step [100/178], Loss: 0.6478
Epoch [15/100], Train Acc 75.37%, Test Acc 68.46%
Epoch [16/100], Step [100/178], Loss: 0.2427
Epoch [16/100], Train Acc 79.60%, Test Acc 73.03%
Epoch [17/100], Step [100/178], Loss: 0.3382
Epoch [17/100], Train Acc 76.11%, Test Acc 72.06%
Epoch [18/100], Step [100/178], Loss: 0.7250
Epoch [18/100], Train Acc 79.22%, Test Acc 75.10%
Epoch [19/100], Step [100/178], Loss: 0.2966
Epoch [19/100], Train Acc 78.09%, Test Acc 71.78%
Epoch [20/100], Step [100/178], Loss: 0.5536
Epoch [20/100], Train Acc 80.49%, Test Acc 73.86%
Epoch [21/100], Step [100/178], Loss: 0.3826
Epoch [21/100], Train Acc 80.38%, Test Acc 71.92%
Epoch [22/100], Step [100/178], Loss: 0.3082
Epoch [22/100], Train Acc 80.45%, Test Acc 72.61%
Epoch [23/100], Step [100/178], Loss: 0.3015
Epoch [23/100], Train Acc 79.85%, Test Acc 72.06%
Epoch [24/100], Step [100/178], Loss: 0.8182
Epoch [24/100], Train Acc 83.38%, Test Acc 73.58%
Epoch [25/100], Step [100/178], Loss: 0.6543
Epoch [25/100], Train Acc 81.65%, Test Acc 72.75%
Epoch [26/100], Step [100/178], Loss: 0.4695
Epoch [26/100], Train Acc 82.36%, Test Acc 72.48%
Epoch [27/100], Step [100/178], Loss: 0.4493
Epoch [27/100], Train Acc 82.00%, Test Acc 70.82%
Epoch [28/100], Step [100/178], Loss: 0.8471
Epoch [28/100], Train Acc 82.11%, Test Acc 69.71%
Epoch [29/100], Step [100/178], Loss: 0.3528
Epoch [29/100], Train Acc 81.86%, Test Acc 71.92%
Epoch [30/100], Step [100/178], Loss: 0.4596
Epoch [30/100], Train Acc 83.77%, Test Acc 73.44%
Epoch [31/100], Step [100/178], Loss: 0.2753
Epoch [31/100], Train Acc 83.38%, Test Acc 71.09%
Epoch [32/100], Step [100/178], Loss: 0.5353
Epoch [32/100], Train Acc 83.70%, Test Acc 72.20%
Epoch [33/100], Step [100/178], Loss: 0.5574
Epoch [33/100], Train Acc 85.22%, Test Acc 74.00%
Epoch [34/100], Step [100/178], Loss: 0.2007
Epoch [34/100], Train Acc 84.93%, Test Acc 74.69%
Epoch [35/100], Step [100/178], Loss: 0.2555
Epoch [35/100], Train Acc 85.85%, Test Acc 73.31%
Epoch [36/100], Step [100/178], Loss: 0.2705
Epoch [36/100], Train Acc 82.82%, Test Acc 70.95%
Epoch [37/100], Step [100/178], Loss: 0.3422
Epoch [37/100], Train Acc 86.17%, Test Acc 72.34%
Epoch [38/100], Step [100/178], Loss: 0.2565
Epoch [38/100], Train Acc 86.41%, Test Acc 72.89%
Epoch [39/100], Step [100/178], Loss: 0.4206
Epoch [39/100], Train Acc 86.13%, Test Acc 72.34%
Epoch [40/100], Step [100/178], Loss: 0.4561
Epoch [40/100], Train Acc 86.91%, Test Acc 73.58%
Epoch [41/100], Step [100/178], Loss: 0.3472
Epoch [41/100], Train Acc 86.66%, Test Acc 72.34%
Epoch [42/100], Step [100/178], Loss: 0.5905
Epoch [42/100], Train Acc 87.69%, Test Acc 73.17%
Epoch [43/100], Step [100/178], Loss: 0.2939
Epoch [43/100], Train Acc 87.47%, Test Acc 72.06%
Epoch [44/100], Step [100/178], Loss: 0.3421
Epoch [44/100], Train Acc 85.39%, Test Acc 72.20%
Epoch [45/100], Step [100/178], Loss: 0.4058
Epoch [45/100], Train Acc 88.04%, Test Acc 72.06%
Epoch [46/100], Step [100/178], Loss: 0.5634
Epoch [46/100], Train Acc 88.50%, Test Acc 71.51%
Epoch [47/100], Step [100/178], Loss: 0.4004
Epoch [47/100], Train Acc 88.14%, Test Acc 69.71%
Epoch [48/100], Step [100/178], Loss: 0.1993
Epoch [48/100], Train Acc 89.17%, Test Acc 70.95%
Epoch [49/100], Step [100/178], Loss: 0.3073
Epoch [49/100], Train Acc 88.32%, Test Acc 70.68%
Epoch [50/100], Step [100/178], Loss: 0.2742
Epoch [50/100], Train Acc 90.51%, Test Acc 72.75%
Epoch [51/100], Step [100/178], Loss: 0.0611
Epoch [51/100], Train Acc 89.24%, Test Acc 70.26%
Epoch [52/100], Step [100/178], Loss: 0.3423
Epoch [52/100], Train Acc 87.16%, Test Acc 69.57%
Epoch [53/100], Step [100/178], Loss: 0.2891
Epoch [53/100], Train Acc 90.72%, Test Acc 70.26%
Epoch [54/100], Step [100/178], Loss: 0.2075
Epoch [54/100], Train Acc 90.76%, Test Acc 70.54%
Epoch [55/100], Step [100/178], Loss: 0.1008
Epoch [55/100], Train Acc 90.33%, Test Acc 72.06%
Epoch [56/100], Step [100/178], Loss: 0.2047
Epoch [56/100], Train Acc 91.92%, Test Acc 71.65%
Epoch [57/100], Step [100/178], Loss: 0.3195
Epoch [57/100], Train Acc 92.66%, Test Acc 70.40%
Epoch [58/100], Step [100/178], Loss: 0.1191
Epoch [58/100], Train Acc 91.64%, Test Acc 70.82%
Epoch [59/100], Step [100/178], Loss: 0.2300
Epoch [59/100], Train Acc 92.63%, Test Acc 71.92%
Epoch [60/100], Step [100/178], Loss: 0.7735
Epoch [60/100], Train Acc 92.98%, Test Acc 70.68%
Epoch [61/100], Step [100/178], Loss: 0.0846
Epoch [61/100], Train Acc 92.45%, Test Acc 70.12%
Epoch [62/100], Step [100/178], Loss: 0.2530
Epoch [62/100], Train Acc 92.10%, Test Acc 69.57%
Epoch [63/100], Step [100/178], Loss: 0.0606
Epoch [63/100], Train Acc 93.75%, Test Acc 69.71%
Epoch [64/100], Step [100/178], Loss: 0.0744
Epoch [64/100], Train Acc 93.61%, Test Acc 68.74%
Epoch [65/100], Step [100/178], Loss: 0.4511
Epoch [65/100], Train Acc 93.61%, Test Acc 68.05%
Epoch [66/100], Step [100/178], Loss: 0.1801
Epoch [66/100], Train Acc 93.93%, Test Acc 68.60%
Epoch [67/100], Step [100/178], Loss: 0.2295
Epoch [67/100], Train Acc 94.32%, Test Acc 69.71%
Epoch [68/100], Step [100/178], Loss: 0.1164
Epoch [68/100], Train Acc 94.71%, Test Acc 69.02%
Epoch [69/100], Step [100/178], Loss: 0.2537
Epoch [69/100], Train Acc 93.82%, Test Acc 68.88%
Epoch [70/100], Step [100/178], Loss: 0.7529
Epoch [70/100], Train Acc 95.55%, Test Acc 69.99%
Epoch [71/100], Step [100/178], Loss: 0.2373
Epoch [71/100], Train Acc 95.55%, Test Acc 69.43%
Epoch [72/100], Step [100/178], Loss: 0.1020
Epoch [72/100], Train Acc 95.59%, Test Acc 69.02%
Epoch [73/100], Step [100/178], Loss: 0.0062
Epoch [73/100], Train Acc 96.40%, Test Acc 69.71%
Epoch [74/100], Step [100/178], Loss: 0.0268
Epoch [74/100], Train Acc 96.29%, Test Acc 69.29%
Epoch [75/100], Step [100/178], Loss: 0.0226
Epoch [75/100], Train Acc 96.22%, Test Acc 69.02%
Epoch [76/100], Step [100/178], Loss: 0.0765
Epoch [76/100], Train Acc 96.68%, Test Acc 69.57%
Epoch [77/100], Step [100/178], Loss: 0.1025
Epoch [77/100], Train Acc 97.00%, Test Acc 67.77%
Epoch [78/100], Step [100/178], Loss: 0.0337
Epoch [78/100], Train Acc 96.72%, Test Acc 67.63%
Epoch [79/100], Step [100/178], Loss: 0.0574
Epoch [79/100], Train Acc 96.86%, Test Acc 68.05%
Epoch [80/100], Step [100/178], Loss: 0.0027
Epoch [80/100], Train Acc 96.82%, Test Acc 66.53%
Epoch [81/100], Step [100/178], Loss: 0.1257
Epoch [81/100], Train Acc 97.25%, Test Acc 68.33%
Epoch [82/100], Step [100/178], Loss: 0.1122
Epoch [82/100], Train Acc 97.81%, Test Acc 68.74%
Epoch [83/100], Step [100/178], Loss: 0.0244
Epoch [83/100], Train Acc 97.28%, Test Acc 68.33%
Epoch [84/100], Step [100/178], Loss: 0.0145
Epoch [84/100], Train Acc 97.46%, Test Acc 67.08%
Epoch [85/100], Step [100/178], Loss: 0.0112
Epoch [85/100], Train Acc 97.60%, Test Acc 67.77%
Epoch [86/100], Step [100/178], Loss: 0.0563
Epoch [86/100], Train Acc 97.95%, Test Acc 67.50%
Epoch [87/100], Step [100/178], Loss: 0.1904
Epoch [87/100], Train Acc 97.67%, Test Acc 67.36%
Epoch [88/100], Step [100/178], Loss: 0.1420
Epoch [88/100], Train Acc 97.74%, Test Acc 67.50%
Epoch [89/100], Step [100/178], Loss: 0.0054
Epoch [89/100], Train Acc 97.85%, Test Acc 66.94%
Epoch [90/100], Step [100/178], Loss: 0.0770
Epoch [90/100], Train Acc 98.06%, Test Acc 67.63%
Epoch [91/100], Step [100/178], Loss: 0.0314
Epoch [91/100], Train Acc 97.99%, Test Acc 67.50%
Epoch [92/100], Step [100/178], Loss: 0.0409
Epoch [92/100], Train Acc 98.38%, Test Acc 67.77%
Epoch [93/100], Step [100/178], Loss: 0.0073
Epoch [93/100], Train Acc 97.92%, Test Acc 66.94%
Epoch [94/100], Step [100/178], Loss: 0.0097
Epoch [94/100], Train Acc 98.24%, Test Acc 67.36%
Epoch [95/100], Step [100/178], Loss: 0.0079
Epoch [95/100], Train Acc 98.45%, Test Acc 67.36%
Epoch [96/100], Step [100/178], Loss: 0.1551
Epoch [96/100], Train Acc 98.34%, Test Acc 67.50%
Epoch [97/100], Step [100/178], Loss: 0.0213
Epoch [97/100], Train Acc 98.20%, Test Acc 67.36%
Epoch [98/100], Step [100/178], Loss: 0.0307
Epoch [98/100], Train Acc 98.38%, Test Acc 67.50%
Epoch [99/100], Step [100/178], Loss: 0.0116
Epoch [99/100], Train Acc 98.34%, Test Acc 67.50%
Epoch [100/100], Step [100/178], Loss: 0.0055
Epoch [100/100], Train Acc 98.38%, Test Acc 67.50%
1700275013.7233675
 Elapsed time: 25.60391536553701 minutes
 Elapsed time: 0.42673192275895017 hours
1700275013.7233753
Saved model to /mmfs1/gscratch/stf/upanpra/model_checkpointsAK/model-VIs-conv_next_model-1700273477.4442928.pt
[[ 70  16  59]
 [ 17 120  59]
 [ 47  37 298]]
[[0.48275862 0.11034483 0.40689655]
 [0.08673469 0.6122449  0.30102041]
 [0.12303665 0.09685864 0.78010471]]
[[0.52238806 0.09248555 0.14182692]
 [0.12686567 0.69364162 0.14182692]
 [0.35074627 0.21387283 0.71634615]]
