Running script with arguments: Namespace(input_channels=44, input_size=[16, 16], modality='hyper', num_classes=3, test_folder=['/mmfs1/gscratch/stf/upanpra/AK_paper_data/16crops/hardwood_vs_softwood/vis/test'], train_folder=['/mmfs1/gscratch/stf/upanpra/AK_paper_data/16crops/hardwood_vs_softwood/vis/train'])
tensor([ 1.2413e-03,  1.3992e+00,  1.5666e-01,  2.4665e-03,  3.7055e-03,
         2.8208e-01,  2.4620e-01,  1.1281e-02,  5.7995e+07,  3.3269e-01,
         1.0076e+00,  1.0347e+03,  1.0074e+03,  1.0008e+03,  4.0351e+00,
         2.8078e+00,  1.4801e+00,  6.4264e-01,  1.7263e+00,  1.6173e+03,
         7.6670e-01,  3.2386e-01,  2.9248e+00,  4.8894e+00,  1.6173e+03,
         7.6670e-01,  6.7660e-01, -2.4590e-02,  1.6352e-01,  6.7651e-01,
        -6.2282e-02,  1.1902e+00,  6.5222e-01,  4.6292e-02,  6.9664e+00,
         6.5256e-01,  3.7723e-01,  6.9674e+02,  8.9830e-01,  7.0955e-01,
         1.0268e+00,  6.1569e+04,  9.7964e-01,  1.4239e+00])
tensor([4.2835e-04, 4.0767e-01, 6.8023e-02, 1.5014e-03, 1.7588e-03, 4.3323e-02,
        4.0901e-02, 2.5345e-03, 2.5077e+07, 2.5095e-01, 2.5432e-01, 2.0523e+02,
        1.9951e+02, 2.0219e+02, 5.4792e-01, 3.3658e-01, 1.8284e-01, 8.7965e-02,
        4.7020e-01, 3.2467e+02, 4.8012e-02, 3.8059e-02, 5.3951e-01, 9.9058e-01,
        3.2467e+02, 4.8012e-02, 4.9931e-02, 3.5875e-02, 6.8917e-02, 4.9927e-02,
        1.4947e-02, 1.0155e-01, 4.8966e-02, 1.9410e-02, 1.3976e+00, 1.7419e-01,
        3.9700e-02, 9.5890e+00, 5.9467e-02, 9.4901e-02, 3.9157e-01, 1.2540e+04,
        2.3095e-01, 7.1845e-02])
Saving model to: /mmfs1/gscratch/stf/upanpra/model_checkpointsAK/best-test-model-VisDroughtCNN-1700280434.6209753.pt
DroughtCNN(
  (conv1): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=512, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=4, bias=True)
)
28338007.244017888
Epoch [1/100], Step [100/178], Loss: 0.7671
Epoch [1/100], Train Acc 65.70%, Test Acc 64.45%
Epoch [2/100], Step [100/178], Loss: 0.4195
Epoch [2/100], Train Acc 64.93%, Test Acc 61.55%
Epoch [3/100], Step [100/178], Loss: 0.7370
Epoch [3/100], Train Acc 69.48%, Test Acc 66.94%
Epoch [4/100], Step [100/178], Loss: 0.6575
Epoch [4/100], Train Acc 71.98%, Test Acc 69.02%
Epoch [5/100], Step [100/178], Loss: 0.8121
Epoch [5/100], Train Acc 70.54%, Test Acc 69.43%
Epoch [6/100], Step [100/178], Loss: 0.7508
Epoch [6/100], Train Acc 66.90%, Test Acc 65.84%
Epoch [7/100], Step [100/178], Loss: 0.5679
Epoch [7/100], Train Acc 73.36%, Test Acc 69.43%
Epoch [8/100], Step [100/178], Loss: 0.3390
Epoch [8/100], Train Acc 69.37%, Test Acc 64.32%
Epoch [9/100], Step [100/178], Loss: 0.5731
Epoch [9/100], Train Acc 72.23%, Test Acc 69.02%
Epoch [10/100], Step [100/178], Loss: 0.8387
Epoch [10/100], Train Acc 73.64%, Test Acc 69.71%
Epoch [11/100], Step [100/178], Loss: 0.5105
Epoch [11/100], Train Acc 75.02%, Test Acc 69.43%
Epoch [12/100], Step [100/178], Loss: 1.1984
Epoch [12/100], Train Acc 73.22%, Test Acc 70.40%
Epoch [13/100], Step [100/178], Loss: 0.5905
Epoch [13/100], Train Acc 73.43%, Test Acc 71.65%
Epoch [14/100], Step [100/178], Loss: 0.9735
Epoch [14/100], Train Acc 73.29%, Test Acc 68.88%
Epoch [15/100], Step [100/178], Loss: 0.5270
Epoch [15/100], Train Acc 75.05%, Test Acc 70.68%
Epoch [16/100], Step [100/178], Loss: 0.5323
Epoch [16/100], Train Acc 74.84%, Test Acc 69.57%
Epoch [17/100], Step [100/178], Loss: 0.5237
Epoch [17/100], Train Acc 73.18%, Test Acc 68.46%
Epoch [18/100], Step [100/178], Loss: 0.8318
Epoch [18/100], Train Acc 71.24%, Test Acc 65.56%
Epoch [19/100], Step [100/178], Loss: 0.5264
Epoch [19/100], Train Acc 72.97%, Test Acc 67.91%
Epoch [20/100], Step [100/178], Loss: 0.6031
Epoch [20/100], Train Acc 74.77%, Test Acc 69.02%
Epoch [21/100], Step [100/178], Loss: 0.3980
Epoch [21/100], Train Acc 75.94%, Test Acc 73.17%
Epoch [22/100], Step [100/178], Loss: 0.6555
Epoch [22/100], Train Acc 67.61%, Test Acc 64.73%
Epoch [23/100], Step [100/178], Loss: 0.4042
Epoch [23/100], Train Acc 76.53%, Test Acc 71.51%
Epoch [24/100], Step [100/178], Loss: 0.6280
Epoch [24/100], Train Acc 76.01%, Test Acc 69.57%
Epoch [25/100], Step [100/178], Loss: 0.4205
Epoch [25/100], Train Acc 77.59%, Test Acc 69.57%
Epoch [26/100], Step [100/178], Loss: 0.5169
Epoch [26/100], Train Acc 76.46%, Test Acc 68.88%
Epoch [27/100], Step [100/178], Loss: 1.0115
Epoch [27/100], Train Acc 78.79%, Test Acc 73.86%
Epoch [28/100], Step [100/178], Loss: 0.5770
Epoch [28/100], Train Acc 78.19%, Test Acc 68.33%
Epoch [29/100], Step [100/178], Loss: 0.5570
Epoch [29/100], Train Acc 77.17%, Test Acc 71.51%
Epoch [30/100], Step [100/178], Loss: 0.5095
Epoch [30/100], Train Acc 78.02%, Test Acc 70.68%
Epoch [31/100], Step [100/178], Loss: 0.4432
Epoch [31/100], Train Acc 77.42%, Test Acc 68.74%
Epoch [32/100], Step [100/178], Loss: 0.2845
Epoch [32/100], Train Acc 75.76%, Test Acc 65.28%
Epoch [33/100], Step [100/178], Loss: 0.8716
Epoch [33/100], Train Acc 76.46%, Test Acc 66.94%
Epoch [34/100], Step [100/178], Loss: 0.6928
Epoch [34/100], Train Acc 78.79%, Test Acc 72.34%
Epoch [35/100], Step [100/178], Loss: 0.5416
Epoch [35/100], Train Acc 80.38%, Test Acc 72.89%
Epoch [36/100], Step [100/178], Loss: 0.4608
Epoch [36/100], Train Acc 76.39%, Test Acc 70.26%
Epoch [37/100], Step [100/178], Loss: 0.3750
Epoch [37/100], Train Acc 78.62%, Test Acc 69.85%
Epoch [38/100], Step [100/178], Loss: 0.3720
Epoch [38/100], Train Acc 78.51%, Test Acc 69.29%
Epoch [39/100], Step [100/178], Loss: 0.4704
Epoch [39/100], Train Acc 80.98%, Test Acc 73.03%
Epoch [40/100], Step [100/178], Loss: 0.2391
Epoch [40/100], Train Acc 81.44%, Test Acc 72.34%
Epoch [41/100], Step [100/178], Loss: 0.3534
Epoch [41/100], Train Acc 81.19%, Test Acc 70.40%
Epoch [42/100], Step [100/178], Loss: 0.4428
Epoch [42/100], Train Acc 79.68%, Test Acc 70.68%
Epoch [43/100], Step [100/178], Loss: 0.3862
Epoch [43/100], Train Acc 80.38%, Test Acc 69.57%
Epoch [44/100], Step [100/178], Loss: 0.4213
Epoch [44/100], Train Acc 80.03%, Test Acc 69.71%
Epoch [45/100], Step [100/178], Loss: 0.8052
Epoch [45/100], Train Acc 81.51%, Test Acc 70.95%
Epoch [46/100], Step [100/178], Loss: 0.7305
Epoch [46/100], Train Acc 81.69%, Test Acc 73.03%
Epoch [47/100], Step [100/178], Loss: 0.3194
Epoch [47/100], Train Acc 79.82%, Test Acc 68.05%
Epoch [48/100], Step [100/178], Loss: 0.5196
Epoch [48/100], Train Acc 81.09%, Test Acc 68.46%
Epoch [49/100], Step [100/178], Loss: 0.4485
Epoch [49/100], Train Acc 83.31%, Test Acc 70.68%
Epoch [50/100], Step [100/178], Loss: 0.4368
Epoch [50/100], Train Acc 79.43%, Test Acc 65.84%
Epoch [51/100], Step [100/178], Loss: 0.3628
Epoch [51/100], Train Acc 82.11%, Test Acc 69.71%
Epoch [52/100], Step [100/178], Loss: 0.3254
Epoch [52/100], Train Acc 83.70%, Test Acc 72.06%
Epoch [53/100], Step [100/178], Loss: 0.7627
Epoch [53/100], Train Acc 83.38%, Test Acc 71.23%
Epoch [54/100], Step [100/178], Loss: 0.2274
Epoch [54/100], Train Acc 79.75%, Test Acc 69.43%
Epoch [55/100], Step [100/178], Loss: 0.3810
Epoch [55/100], Train Acc 83.20%, Test Acc 71.23%
Epoch [56/100], Step [100/178], Loss: 0.3850
Epoch [56/100], Train Acc 80.77%, Test Acc 72.06%
Epoch [57/100], Step [100/178], Loss: 0.4412
Epoch [57/100], Train Acc 83.70%, Test Acc 71.23%
Epoch [58/100], Step [100/178], Loss: 0.5961
Epoch [58/100], Train Acc 77.95%, Test Acc 68.05%
Epoch [59/100], Step [100/178], Loss: 0.2682
Epoch [59/100], Train Acc 83.13%, Test Acc 70.26%
Epoch [60/100], Step [100/178], Loss: 0.3524
Epoch [60/100], Train Acc 79.96%, Test Acc 69.16%
Epoch [61/100], Step [100/178], Loss: 0.2418
Epoch [61/100], Train Acc 83.80%, Test Acc 71.65%
Epoch [62/100], Step [100/178], Loss: 0.5866
Epoch [62/100], Train Acc 82.07%, Test Acc 69.02%
Epoch [63/100], Step [100/178], Loss: 1.1111
Epoch [63/100], Train Acc 82.71%, Test Acc 68.74%
Epoch [64/100], Step [100/178], Loss: 0.2471
Epoch [64/100], Train Acc 79.46%, Test Acc 69.29%
Epoch [65/100], Step [100/178], Loss: 0.4254
Epoch [65/100], Train Acc 80.38%, Test Acc 69.02%
Epoch [66/100], Step [100/178], Loss: 0.4060
Epoch [66/100], Train Acc 84.65%, Test Acc 72.34%
Epoch [67/100], Step [100/178], Loss: 0.5509
Epoch [67/100], Train Acc 84.62%, Test Acc 69.43%
Epoch [68/100], Step [100/178], Loss: 0.2312
Epoch [68/100], Train Acc 82.92%, Test Acc 70.26%
Epoch [69/100], Step [100/178], Loss: 0.4885
Epoch [69/100], Train Acc 85.22%, Test Acc 70.82%
Epoch [70/100], Step [100/178], Loss: 0.7812
Epoch [70/100], Train Acc 86.13%, Test Acc 72.20%
Epoch [71/100], Step [100/178], Loss: 0.4672
Epoch [71/100], Train Acc 85.18%, Test Acc 72.75%
Epoch [72/100], Step [100/178], Loss: 0.3005
Epoch [72/100], Train Acc 86.52%, Test Acc 70.26%
Epoch [73/100], Step [100/178], Loss: 0.8018
Epoch [73/100], Train Acc 84.26%, Test Acc 69.71%
Epoch [74/100], Step [100/178], Loss: 0.3162
Epoch [74/100], Train Acc 86.73%, Test Acc 72.34%
Epoch [75/100], Step [100/178], Loss: 0.1783
Epoch [75/100], Train Acc 86.70%, Test Acc 72.75%
Epoch [76/100], Step [100/178], Loss: 0.5063
Epoch [76/100], Train Acc 86.06%, Test Acc 70.12%
Epoch [77/100], Step [100/178], Loss: 0.5200
Epoch [77/100], Train Acc 86.94%, Test Acc 71.37%
Epoch [78/100], Step [100/178], Loss: 0.0619
Epoch [78/100], Train Acc 85.14%, Test Acc 71.23%
Epoch [79/100], Step [100/178], Loss: 0.1773
Epoch [79/100], Train Acc 84.65%, Test Acc 69.43%
Epoch [80/100], Step [100/178], Loss: 0.5267
Epoch [80/100], Train Acc 87.30%, Test Acc 70.40%
Epoch [81/100], Step [100/178], Loss: 0.2129
Epoch [81/100], Train Acc 87.54%, Test Acc 70.54%
Epoch [82/100], Step [100/178], Loss: 0.9529
Epoch [82/100], Train Acc 86.17%, Test Acc 69.99%
Epoch [83/100], Step [100/178], Loss: 0.5343
Epoch [83/100], Train Acc 85.25%, Test Acc 69.57%
Epoch [84/100], Step [100/178], Loss: 0.2401
Epoch [84/100], Train Acc 88.43%, Test Acc 69.85%
Epoch [85/100], Step [100/178], Loss: 0.1757
Epoch [85/100], Train Acc 86.38%, Test Acc 69.99%
Epoch [86/100], Step [100/178], Loss: 0.2985
Epoch [86/100], Train Acc 87.37%, Test Acc 70.12%
Epoch [87/100], Step [100/178], Loss: 0.2224
Epoch [87/100], Train Acc 85.22%, Test Acc 70.40%
Epoch [88/100], Step [100/178], Loss: 0.3625
Epoch [88/100], Train Acc 88.99%, Test Acc 72.61%
Epoch [89/100], Step [100/178], Loss: 0.3017
Epoch [89/100], Train Acc 81.02%, Test Acc 66.67%
Epoch [90/100], Step [100/178], Loss: 0.3433
Epoch [90/100], Train Acc 85.32%, Test Acc 69.85%
Epoch [91/100], Step [100/178], Loss: 0.6828
Epoch [91/100], Train Acc 88.64%, Test Acc 72.48%
Epoch [92/100], Step [100/178], Loss: 0.2202
Epoch [92/100], Train Acc 86.91%, Test Acc 72.20%
Epoch [93/100], Step [100/178], Loss: 0.7315
Epoch [93/100], Train Acc 87.90%, Test Acc 71.09%
Epoch [94/100], Step [100/178], Loss: 0.3107
Epoch [94/100], Train Acc 85.22%, Test Acc 68.88%
Epoch [95/100], Step [100/178], Loss: 0.3130
Epoch [95/100], Train Acc 86.56%, Test Acc 69.16%
Epoch [96/100], Step [100/178], Loss: 0.3696
Epoch [96/100], Train Acc 87.30%, Test Acc 70.40%
Epoch [97/100], Step [100/178], Loss: 0.4062
Epoch [97/100], Train Acc 85.00%, Test Acc 69.16%
Epoch [98/100], Step [100/178], Loss: 0.1948
Epoch [98/100], Train Acc 84.86%, Test Acc 70.95%
Epoch [99/100], Step [100/178], Loss: 0.2269
Epoch [99/100], Train Acc 84.62%, Test Acc 69.71%
Epoch [100/100], Step [100/178], Loss: 0.6659
Epoch [100/100], Train Acc 87.01%, Test Acc 69.71%
1700281493.4966843
 Elapsed time: 17.647593518098194 minutes
 Elapsed time: 0.2941265586349699 hours
1700281493.4966917
Saved model to /mmfs1/gscratch/stf/upanpra/model_checkpointsAK/model-VIs-DroughtCNN-1700280434.6209753.pt
[[ 64  33  48]
 [ 10 138  48]
 [ 26  53 303]]
[[0.44137931 0.22758621 0.33103448]
 [0.05102041 0.70408163 0.24489796]
 [0.06806283 0.13874346 0.79319372]]
[[0.64       0.14732143 0.12030075]
 [0.1        0.61607143 0.12030075]
 [0.26       0.23660714 0.7593985 ]]
